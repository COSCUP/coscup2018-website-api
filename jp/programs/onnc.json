{"talks":{"onnc":{"talk":"onnc","track":"kernel","speakers":["Luba Tang"],"begin":"2018-08-11T10:45:00+08:00","end":"2018-08-11T11:25:00+08:00","title":"ONNC - Open Neural Network Compiler ","intro":"Hundreds of AI chips are releasing in the near future, the latest figures indicate 34 IC and IP vendors will provide various AI chips and deep learning accelerator (DLA) ASICs in 2018. These all reflect the urgent need for an open compiler to support different AI chips.\n\nWe foresaw the trend and developed the compiler ONNC. Based on ONNX, ONNC is an efficient way to connect all current AI chips, especially DLA ASICs, with ONNX.\n\nOpen Neural Network Exchange Format (ONNX) is a standard for representing deep learning models that enables models to be transferred between frameworks. We introduce ONNC that supports ONNX format and mainstream AI frameworks such as Caffe and Tensorflow. ONNC’s dominant advantage to current AI frameworks is that it provides direct support to DLA ASIC chips by ability to describe variants of performance cost models of hardware and by general optimization passes. DLA ASIC vendors can reuse these optimization passes by describing its special performance cost model in ONNC. ONNX and ONNC together help DLA ASIC vendors support various AI frameworks within a short time, improves DLA’s performance and shortens developing schedule. \n\nONNX aims to guarantee `interoperatability` for all tools, and ONNC further guarantees `executability` for all devices. ","addition":"* Language: 漢語 / Mandarin Chinese\n* Audience: deep learning framework developers\n* Difficulty: Skilled / 中階"}},"tracks":{"kernel":{"group":"kernel","track":"kernel","communities":["kernel"],"room":"IB202"}},"speakers":{"Luba Tang":{"speaker":"Luba Tang","name":"Luba Tang","intro":"Luba Tang received his M.S. degree in computer science in only one year from the National Tsing-Hua University, Taiwan. He has been a Ph.D student in computer science department of National Tsing-Hua University, Taiwan since 2007. At the same time, he has been working in the compiler groups in Marvell, Inc. and MediaTek, Inc. since 2010. His research interests include both eletronic system level (ESL) design and compilers. He had focussed on iterative compiler, ahead-of-time compiler, link-time optimization, electronic system level simulation, and electronic system level design. His most recent work focus is on dynamic lnking and link-time optimization. He was the chief programmer of Starfish DSP simulator, the original writer of Marvell iterative compiler, and the software architect of MCLinker and the founder of Skymizer Inc..","link":"","avatar":"/assets/Luba Tang-1cm3qgl55IqT2ZIecwJzxa-z9eUmTTSrT.png"}},"communities":{"kernel":{"community":"kernel","link":"","image":null}}}